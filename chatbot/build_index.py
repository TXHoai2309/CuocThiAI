import json
import os
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document

# ğŸ“¥ BÆ°á»›c 1: Load dá»¯ liá»‡u JSON (lÃ¹i 1 cáº¥p tá»« chatbot ra CuocThiAI)
file_path = "menu_contents_refined.json"


print(f"ğŸ“‚ Äang má»Ÿ file: {os.path.abspath(file_path)}")  # In Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i

with open(file_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# ğŸ“„ BÆ°á»›c 2: Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh danh sÃ¡ch Document
documents = []
for item in data:
    if "content" in item and item["content"].strip():
        metadata = {
            "title": item.get("title"),
            "url": item.get("url"),
            "category": item.get("category"),
            "date": item.get("date"),
        }

        doc = Document(
            page_content=item["content"],
            metadata=metadata
        )
        documents.append(doc)

# ğŸ¤– BÆ°á»›c 3: Táº¡o Embedding + FAISS index
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = FAISS.from_documents(documents, embedding_model)

# ğŸ’¾ BÆ°á»›c 4: LÆ°u FAISS index
output_path = os.path.join(os.path.dirname(__file__), "..", "data", "hou_index")
db.save_local(output_path)

print("âœ… ÄÃ£ lÆ°u FAISS index vÃ o:", os.path.abspath(output_path))
